Google, Amazon, Microsoft, and Meta all have their own custom chips. 
However, why can't these chips completely replace NVIDIA's chips? 

NVIDIA's primary positioning emphasizes its GPUs and the inherent software stack. 
This is the moat NVIDIA has been dreaming of for a long time. Customers using the cloud do not stick to just one cloud provider. 
They expand their workloads across multiple clouds, and in most cases, developers are reluctant to develop a software stack on top of a specific hyperscaler’s ASIC-based hardware—only a minority do so. 

Because of this, all hyperscalers offer NVIDIA GPU instances. 
For corporate clients who want to build workloads involving a large amount of their own data for on-premises data centers, NVIDIA GPU servers are practically the only solution. 
From a corporate standpoint, being able to operate products and services developed both in the cloud and in-house data centers on a unified CUDA stack, 
despite the high cost... very high cost, makes purchasing NVIDIA’s GPUs a more flexible option that justifies the expense. 
Up until now, that is.

It can be said that buying time with money is similar to frequent occurrences where the fast fish eats the big fish.
